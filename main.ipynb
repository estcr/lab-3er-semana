{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://www.nike.com/es/w?q=metcon&vst=metcon\"\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3',\n",
    "    'Accept-Language': 'en-US,en;q=0.9',\n",
    "    'Accept-Encoding': 'gzip, deflate, br',\n",
    "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',\n",
    "    'Connection': 'keep-alive',\n",
    "    'Upgrade-Insecure-Requests': '1',\n",
    "    'Referer': 'https://www.google.com'\n",
    "}\n",
    "response = requests.get(url,headers=headers)\n",
    "from bs4 import BeautifulSoup\n",
    "soup=BeautifulSoup(response.content, \"html.parser\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import pandas as pd\\nfrom bs4 import BeautifulSoup\\n\\n# Crear DataFrame vacío con las columnas deseadas\\ndf = pd.DataFrame(columns=[\\'title\\', \\'price\\'])\\n\\n# Extraer todas las tarjetas de producto\\nproduct_titles = soup.find_all(\\'div\\', class_=\\'product-card__title\\')\\nproduct_prices = soup.find_all(\\'div\\', class_=\\'product-card__price\\')\\n\\n# Asegurarse de que la longitud de las listas coincida\\nnum_items = min(len(product_titles), len(product_prices))\\n\\n# Iterar sobre las tarjetas y extraer información\\nfor i in range(num_items):\\n    # Obtener el título del producto\\n    title = product_titles[i].text.strip() if product_titles[i] else \"N/A\"\\n    # Obtener el precio del producto\\n    price = product_prices[i].text.strip() if product_prices[i] else \"N/A\"\\n    # Agregar al DataFrame\\n    df.loc[i] = [title, price]\\n\\n# Mostrar el DataFrame resultante\\nprint(df)'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Crear DataFrame vacío con las columnas deseadas\n",
    "df = pd.DataFrame(columns=['title', 'price'])\n",
    "\n",
    "# Extraer todas las tarjetas de producto\n",
    "product_titles = soup.find_all('div', class_='product-card__title')\n",
    "product_prices = soup.find_all('div', class_='product-card__price')\n",
    "\n",
    "# Asegurarse de que la longitud de las listas coincida\n",
    "num_items = min(len(product_titles), len(product_prices))\n",
    "\n",
    "# Iterar sobre las tarjetas y extraer información\n",
    "for i in range(num_items):\n",
    "    # Obtener el título del producto\n",
    "    title = product_titles[i].text.strip() if product_titles[i] else \"N/A\"\n",
    "    # Obtener el precio del producto\n",
    "    price = product_prices[i].text.strip() if product_prices[i] else \"N/A\"\n",
    "    # Agregar al DataFrame\n",
    "    df.loc[i] = [title, price]\n",
    "\n",
    "# Mostrar el DataFrame resultante\n",
    "print(df)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import requests\n",
    "import re\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "def clean_price(price_str):\n",
    "    \"\"\"\n",
    "    Limpia la cadena de precio, eliminando símbolos no numéricos.\n",
    "    \n",
    "    Args:\n",
    "        price_str (str): Cadena con el precio a limpiar.\n",
    "    \n",
    "    Returns:\n",
    "        float: Precio convertido a número.\n",
    "    \"\"\"\n",
    "    # Eliminar símbolos de moneda, espacios especiales y reemplazar coma por punto\n",
    "    clean_str = re.sub(r'[^\\d,.]', '', price_str)\n",
    "    \n",
    "    # Reemplazar coma por punto si es un separador decimal\n",
    "    clean_str = clean_str.replace(',', '.')\n",
    "    \n",
    "    try:\n",
    "        return float(clean_str)\n",
    "    except ValueError:\n",
    "        return float('inf')  # Valor muy alto para comparaciones\n",
    "\n",
    "def extract_product_data(soup):\n",
    "    \"\"\"\n",
    "    Extrae información de los productos, incluyendo títulos, precios, links, descripción y materiales.\n",
    "\n",
    "    Args:\n",
    "        soup (BeautifulSoup): Objeto BeautifulSoup con el HTML parseado.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame con las columnas 'title', 'current_price', 'discount_price',\n",
    "                      'description', 'materials', 'link'.\n",
    "    \"\"\"\n",
    "    # Crear DataFrame vacío con las columnas deseadas\n",
    "    df = pd.DataFrame(columns=['title', 'current_price', 'discount_price', 'description', 'materials', 'link'])\n",
    "\n",
    "    # Extraer todas las tarjetas de producto con los nuevos selectores\n",
    "    product_titles = soup.find_all('div', class_='product-card__title')\n",
    "    product_price_containers = soup.find_all('div', class_='product-card__price')\n",
    "    product_descriptions = soup.find_all('div', class_='product-card__subtitle')\n",
    "    product_materials = soup.find_all('div', class_='product-card__messaging')\n",
    "    product_links = soup.find_all('a', class_='product-card__link-overlay')\n",
    "\n",
    "    # Determinar el número de productos (basado en títulos)\n",
    "    num_items = len(product_titles)\n",
    "\n",
    "    # Iterar sobre las tarjetas de productos y extraer información\n",
    "    for i in range(num_items):\n",
    "        # Pausa para evitar ser bloqueado por el servidor\n",
    "        time.sleep(1)\n",
    "\n",
    "        # Obtener el título del producto\n",
    "        title = product_titles[i].text.strip() if i < len(product_titles) else \"N/A\"\n",
    "\n",
    "        # Obtener los precios\n",
    "        current_price = \"N/A\"\n",
    "        discount_price = \"N/A\"\n",
    "        \n",
    "        if i < len(product_price_containers):\n",
    "            price_wrapper = product_price_containers[i].find('div', class_='product-price__wrapper')\n",
    "            \n",
    "            if price_wrapper:\n",
    "                # Buscar elementos de precio de diferentes clases\n",
    "                price_elems = price_wrapper.find_all('div', class_=['es__styling', 'is--current-price', 'is--original-price'])\n",
    "                \n",
    "                # Filtrar y limpiar precios\n",
    "                prices = [elem.text.strip() for elem in price_elems if elem and elem.text.strip()]\n",
    "                \n",
    "                # Lógica de asignación de precios\n",
    "                if len(prices) >= 2:\n",
    "                    # Ordenar precios de menor a mayor\n",
    "                    sorted_prices = sorted(prices, key=clean_price)\n",
    "                    current_price = sorted_prices[0]\n",
    "                    discount_price = sorted_prices[-1]\n",
    "                elif len(prices) == 1:\n",
    "                    current_price = prices[0]\n",
    "                    discount_price = current_price\n",
    "\n",
    "        # Obtener la descripción del producto\n",
    "        description = product_descriptions[i].text.strip() if i < len(product_descriptions) else \"N/A\"\n",
    "\n",
    "        # Obtener los materiales\n",
    "        materials = product_materials[i].text.strip() if i < len(product_materials) else \"N/A\"\n",
    "\n",
    "        # Obtener el link del producto\n",
    "        link = product_links[i]['href'] if i < len(product_links) else \"N/A\"\n",
    "\n",
    "        # Agregar los datos al DataFrame\n",
    "        df.loc[i] = [title, current_price, discount_price, description, materials, link]\n",
    "\n",
    "    return df\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"df=extract_product_data(soup)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        title current_price discount_price  \\\n",
      "0          Nike Free Metcon 6      103,99 €       129,99 €   \n",
      "1          Nike Free Metcon 6      129,99 €       129,99 €   \n",
      "2               Nike Metcon 9       97,99 €       139,99 €   \n",
      "3               Nike Metcon 9       97,99 €       139,99 €   \n",
      "4               Nike Metcon 9      139,99 €       139,99 €   \n",
      "5           Nike Metcon 9 AMP      149,99 €       149,99 €   \n",
      "6            Nike Metcon 1 OG      104,99 €       149,99 €   \n",
      "7           Nike Metcon 9 AMP      149,99 €       149,99 €   \n",
      "8        Nike Metcon 9 EasyOn       97,99 €       139,99 €   \n",
      "9               Nike Metcon 9      139,99 €       139,99 €   \n",
      "10              Nike Metcon 9      139,99 €       139,99 €   \n",
      "11       Nike Metcon 9 By You      169,99 €       169,99 €   \n",
      "12       Nike Metcon 9 By You      169,99 €       169,99 €   \n",
      "13  Nike Free Metcon 6 By You      159,99 €       159,99 €   \n",
      "\n",
      "                                        description               materials  \\\n",
      "0                    Zapatillas de training - Mujer  Materiales sostenibles   \n",
      "1                   Zapatillas de training - Hombre  Materiales sostenibles   \n",
      "2                    Zapatillas de training - Mujer  Materiales sostenibles   \n",
      "3                   Zapatillas de training - Hombre  Materiales sostenibles   \n",
      "4                   Zapatillas de training - Hombre  Materiales sostenibles   \n",
      "5                    Zapatillas de training - Mujer  Materiales sostenibles   \n",
      "6                   Zapatillas de training - Hombre  Materiales sostenibles   \n",
      "7                   Zapatillas de training - Hombre  Materiales sostenibles   \n",
      "8                    Zapatillas de training - Mujer  Materiales sostenibles   \n",
      "9                   Zapatillas de training - Hombre  Materiales sostenibles   \n",
      "10                  Zapatillas de training - Hombre            Personalizar   \n",
      "11   Zapatillas de training personalizables - Mujer            Personalizar   \n",
      "12  Zapatillas de training personalizables - Hombre            Personalizar   \n",
      "13      Zapatillas de entrenamiento personalizables                     N/A   \n",
      "\n",
      "                                                 link  \n",
      "0   https://www.nike.com/es/t/free-metcon-6-zapati...  \n",
      "1   https://www.nike.com/es/t/free-metcon-6-zapati...  \n",
      "2   https://www.nike.com/es/t/metcon-9-zapatillas-...  \n",
      "3   https://www.nike.com/es/t/metcon-9-zapatillas-...  \n",
      "4   https://www.nike.com/es/t/metcon-9-zapatillas-...  \n",
      "5   https://www.nike.com/es/t/metcon-9-amp-zapatil...  \n",
      "6   https://www.nike.com/es/t/metcon-1-og-zapatill...  \n",
      "7   https://www.nike.com/es/t/metcon-9-amp-zapatil...  \n",
      "8   https://www.nike.com/es/t/metcon-9-easyon-zapa...  \n",
      "9   https://www.nike.com/es/t/metcon-9-zapatillas-...  \n",
      "10  https://www.nike.com/es/t/metcon-9-zapatillas-...  \n",
      "11  https://www.nike.com/es/u/custom-nike-metcon-9...  \n",
      "12  https://www.nike.com/es/u/custom-nike-metcon-9...  \n",
      "13  https://www.nike.com/es/u/custom-free-metcon-6...  \n"
     ]
    }
   ],
   "source": [
    "\"\"\"print (df)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el DataFrame como un archivo CSV\n",
    "df.to_csv('productos_metcon.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nREEBOK\\nimport requests\\nimport pandas as pd\\nimport time\\n\\nurl2 = \"https://www.reebok.eu/es-es/shopping/?query=nano&pageindex=1\"\\n\\nheaders = {\\n    \\'User-Agent\\': \\'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3\\',\\n    \\'Accept-Language\\': \\'en-US,en;q=0.9\\',\\n    \\'Accept-Encoding\\': \\'gzip, deflate, br\\',\\n    \\'Accept\\': \\'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8\\',\\n    \\'Connection\\': \\'keep-alive\\',\\n    \\'Upgrade-Insecure-Requests\\': \\'1\\',\\n    \\'Referer\\': \\'https://www.google.com\\'\\n}\\nresponse2 = requests.get(url2,headers=headers)\\nfrom bs4 import BeautifulSoup\\nsoup2=BeautifulSoup(response.content, \"html.parser\")\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "REEBOK\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "url2 = \"https://www.reebok.eu/es-es/shopping/?query=nano&pageindex=1\"\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3',\n",
    "    'Accept-Language': 'en-US,en;q=0.9',\n",
    "    'Accept-Encoding': 'gzip, deflate, br',\n",
    "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',\n",
    "    'Connection': 'keep-alive',\n",
    "    'Upgrade-Insecure-Requests': '1',\n",
    "    'Referer': 'https://www.google.com'\n",
    "}\n",
    "response2 = requests.get(url2,headers=headers)\n",
    "from bs4 import BeautifulSoup\n",
    "soup2=BeautifulSoup(response.content, \"html.parser\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (2363062143.py, line 14)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[8], line 14\u001b[1;36m\u001b[0m\n\u001b[1;33m    Extrae los títulos y precios de los productos desde el HTML.\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "REEBOK\n",
    "\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def extract_product_data1(soup2):\n",
    "    \"\"\"\n",
    "    Extrae los títulos y precios de los productos desde el HTML.\n",
    "    \n",
    "    Args:\n",
    "        soup (BeautifulSoup): Objeto BeautifulSoup con el HTML parseado.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame con las columnas 'title' y 'price'.\n",
    "    \"\"\"\n",
    "    # Crear DataFrame vacío\n",
    "    df2 = pd.DataFrame(columns=['title', 'price'])\n",
    "\n",
    "    # Extraer títulos y precios\n",
    "    product_titles = soup.find_all('a', class_='css-6q57t3')\n",
    "    product_prices = soup2.find_all('span', class_='css-gz3xcd')  # Extraer precios\n",
    "\n",
    "    print(product_titles)\n",
    "\n",
    "    items = min(len(product_titles), len(product_prices))\n",
    "\n",
    "    # Iterar sobre las tarjetas y extraer información\n",
    "    for i in range(items):\n",
    "        # Pausa para evitar ser bloqueado por el servidor\n",
    "        time.sleep(1)\n",
    "\n",
    "        # Obtener el título del producto\n",
    "        title = product_titles[i].text.strip()\n",
    "\n",
    "        # Obtener el precio del producto\n",
    "        price = product_prices[i].text.strip()\n",
    "\n",
    "        # Agregar al DataFrame\n",
    "        df2.loc[i] = [title, price]\n",
    "\n",
    "    return df2\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "# Configuración de Selenium\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "\n",
    "# Abrir la página con Selenium\n",
    "driver.get(url2)\n",
    "\n",
    "# Esperar a que la página cargue (puedes aumentar el tiempo si es necesario)\n",
    "time.sleep(5)  # Asegúrate de que la página esté completamente cargada\n",
    "\n",
    "# Obtener el HTML final después de la ejecución de JavaScript\n",
    "html = driver.page_source\n",
    "\n",
    "# Parsear el HTML con BeautifulSoup\n",
    "soup2 = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# Buscar los títulos de los productos\n",
    "product_titles = soup2.find_all('a', class_='css-6q57t3')\n",
    "\n",
    "# Imprimir los títulos\n",
    "for title in product_titles:\n",
    "    print(title.text.strip())\n",
    "\n",
    "# Cerrar el navegador\n",
    "driver.quit()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://www.google.com/search?sca_esv=52b786e3c32e91aa&sxsrf=ADLYWIJzaQNUCwpre5WGXnxllDwObD2FDQ:1732010609255&q=nano+x4&udm=3&fbs=AEQNm0Aa4sjWe7Rqy32pFwRj0UkW-OQaqdGt8z1nDoaJBZXQXrjV_FGaE-ipftVLDeuC-qMh4iVV89uznMMk96EaufLpeZ3tfP7l5MquR682bCvg97GMvSYBUPWuK4K84eg6ZDjI4f014IBjhX15i8vl_SA7_i5z_gvuNM3QASMWU6Q-KkcZxZM4jb8N5mwHrOOHrIIGSKdC&sa=X&ved=2ahUKEwjchfKokuiJAxVNQ_EDHZGTPLgQs6gLegQIEBAB&biw=1034&bih=869&dpr=1\"\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3',\n",
    "    'Accept-Language': 'en-US,en;q=0.9',\n",
    "    'Accept-Encoding': 'gzip, deflate, br',\n",
    "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',\n",
    "    'Connection': 'keep-alive',\n",
    "    'Upgrade-Insecure-Requests': '1',\n",
    "    'Referer': 'https://www.google.com'\n",
    "}\n",
    "response = requests.get(url,headers=headers)\n",
    "soup=BeautifulSoup(response.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "def extract_product_data(soup):\n",
    "    \"\"\"\n",
    "    Extrae información de los productos, incluyendo títulos, precios, tienda, calificaciones y links.\n",
    "\n",
    "    Args:\n",
    "        soup (BeautifulSoup): Objeto BeautifulSoup con el HTML parseado.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame con las columnas 'title', 'current_price', 'discount_price',\n",
    "                      'shop', 'rating', 'link'.\n",
    "    \"\"\"\n",
    "    # Crear DataFrame vacío con las columnas deseadas\n",
    "    df = pd.DataFrame(columns=['title', 'actual_price', 'current_price', 'shop', 'rating', 'link'])\n",
    "\n",
    "    # Extraer todas las tarjetas de producto\n",
    "    product_titles = soup.find_all('div', class_='gkQHve SsM98d RmEs5b')  # Clase de descripción/título\n",
    "    current_prices = soup.find_all('span', class_='lmQWe pVBUqb')  # Clase de precio actual\n",
    "    normal_prices = soup.find_all('span', class_='DoCHT Y1xxFf FAayse iDE0Tc')  # Clase de precio normal\n",
    "    shops = soup.find_all('span', class_='WJMUdc rw5ecc')  # Clase de tienda\n",
    "    ratings = soup.find_all('span', class_='z3HNkc')  # Clase de calificación\n",
    "    \n",
    "    # Determinar el número de productos (basado en títulos)\n",
    "    num_items = len(product_titles)\n",
    "\n",
    "    # Iterar sobre las tarjetas de productos y extraer información\n",
    "    for i in range(num_items):\n",
    "        time.sleep(0.5)  # Pausa para evitar ser bloqueado\n",
    "\n",
    "        # Obtener el título del producto\n",
    "        title = product_titles[i].text.strip() if i < len(product_titles) else \"N/A\"\n",
    "\n",
    "        # Obtener el precio actual\n",
    "        current_price = current_prices[i].text.strip() if i < len(current_prices) else \"N/A\"\n",
    "\n",
    "        # Obtener el precio normal\n",
    "        actual_price = normal_prices[i].text.strip() if i < len(normal_prices) else \"N/A\"\n",
    "\n",
    "        # Obtener la tienda\n",
    "        shop = shops[i].text.strip() if i < len(shops) else \"N/A\"\n",
    "\n",
    "        # Obtener el rating\n",
    "        rating = ratings[i].get('aria-label', 'N/A') if i < len(ratings) else \"N/A\"\n",
    "\n",
    "        # Enlace del producto (no aparece claramente en la descripción)\n",
    "        link = \"N/A\"  # Este campo se dejará vacío si no encontramos el enlace.\n",
    "\n",
    "        # Agregar los datos al DataFrame\n",
    "        df.loc[i] = [title, actual_price, current_price, shop, rating, link]\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=extract_product_data(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>current_price</th>\n",
       "      <th>normal_price</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [title, current_price, normal_price, link]\n",
       "Index: []"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "url=\"https://www.fittestfreakest.es/mujer:zapatillas\"\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3',\n",
    "    'Accept-Language': 'en-US,en;q=0.9',\n",
    "    'Accept-Encoding': 'gzip, deflate, br',\n",
    "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',\n",
    "    'Connection': 'keep-alive',\n",
    "    'Upgrade-Insecure-Requests': '1',\n",
    "    'Referer': 'https://www.google.com'\n",
    "}\n",
    "response = requests.get(url,headers=headers)\n",
    "soup=BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "\n",
    "def extract_product_data(soup):\n",
    "    df = pd.DataFrame(columns=['title', 'current_price', 'normal_price', 'link'])\n",
    "\n",
    "    # Extraer títulos\n",
    "    product_titles = soup.find_all('h2', class_='ng-star-inserted')\n",
    "    # Extraer precios\n",
    "    current_prices = soup.find_all('span', class_='is-size-6')\n",
    "    normal_price = soup.find_all('span', class_='is-size-7')\n",
    "    links = soup.find_all('a', class_='ng-star-inserted', href=True)\n",
    "\n",
    "    num_items = len(product_titles)\n",
    "\n",
    "    for i in range(num_items):\n",
    "        title = product_titles[i].text.strip() if i < len(product_titles) else \"N/A\"\n",
    "        current_price = current_prices[i].text.strip() if i < len(current_prices) else \"N/A\"\n",
    "        normal_price = normal_price[i].text.strip() if i < len(normal_price) else \"N/A\"\n",
    "        link = links[i].text.strip() if i < len(links) else \"N/A\"\n",
    "\n",
    "        df.loc[i] = [title, current_price, normal_price, link]\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [title, price]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Crear DataFrame vacío con las columnas deseadas\n",
    "df = pd.DataFrame(columns=['title', 'price'])\n",
    "\n",
    "# Extraer todas las tarjetas de producto\n",
    "product_titles = soup.find_all('div', class_='gkQHve SsM98d RmEs5b')\n",
    "    # Extraer precios\n",
    "product_prices = soup.find_all('span', class_='lmQWe pVBUqb')\n",
    "\n",
    "\n",
    "# Asegurarse de que la longitud de las listas coincida\n",
    "num_items = min(len(product_titles), len(product_prices))\n",
    "\n",
    "# Iterar sobre las tarjetas y extraer información\n",
    "for i in range(num_items):\n",
    "    # Obtener el título del producto\n",
    "    title = product_titles[i].text.strip() if product_titles[i] else \"N/A\"\n",
    "    # Obtener el precio del producto\n",
    "    price = product_prices[i].text.strip() if product_prices[i] else \"N/A\"\n",
    "    # Agregar al DataFrame\n",
    "    df.loc[i] = [title, price]\n",
    "\n",
    "# Mostrar el DataFrame resultante\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "primerlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
